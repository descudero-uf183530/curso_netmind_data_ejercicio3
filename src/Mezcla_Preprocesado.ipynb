{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_selector as selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los tres datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los tres datasets DES:\n",
    "base_url = \"https://raw.githubusercontent.com/ricardoahumada/DataExpert/refs/heads/main/etapa2/data/\"\n",
    "\n",
    "try:\n",
    "    df_original_caracteristicas_equipos = pd.read_csv(base_url + 'Caracteristicas_Equipos.csv')\n",
    "    df_original_historico_ordenes = pd.read_csv(base_url + 'Historicos_Ordenes.csv')\n",
    "    df_original_registros_condiciones = pd.read_csv(base_url + 'Registros_Condiciones.csv')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar los datos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar copia en local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los guardamos en local los originales para no depender.\n",
    "\n",
    "df_original_caracteristicas_equipos.to_csv(\"../output/df_caracteristicas_equipos.csv\", index=False)\n",
    "df_original_historico_ordenes.to_csv(\"../output/df_historico_ordenes.csv\", index=False)\n",
    "df_original_registros_condiciones.to_csv(\"../output/df_registros_condiciones.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los tres datasets desde local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los tres datasets desde local:\n",
    "\n",
    "\n",
    "try:\n",
    "    df_trabajo_caracteristicas_equipos = pd.read_csv(\"../output/df_caracteristicas_equipos.csv\")\n",
    "    df_trabajo_historico_ordenes = pd.read_csv(\"../output/df_historico_ordenes.csv\")\n",
    "    df_trabajo_registros_condiciones = pd.read_csv(\"../output/df_registros_condiciones.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar los datos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado por separado:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar Nulos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_nulos(df):\n",
    "\n",
    "# Esta función verifica si hay valores nulos en el DataFrame.\n",
    "    \n",
    "    nulos = df.isnull().sum().sum()\n",
    "    print(\"Numero nulos=\" + str(nulos))\n",
    "\n",
    "    if nulos != 0:\n",
    "        df.dropna(inplace=True)\n",
    "        print(\"Valores nulos eliminados\")\n",
    "    else:\n",
    "        print(\"No hay valores nulos\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   ID_Equipo                    505 non-null    int64  \n",
      " 1   Tipo_Equipo                  505 non-null    object \n",
      " 2   Fabricante                   505 non-null    object \n",
      " 3   Modelo                       505 non-null    object \n",
      " 4   Potencia_kW                  505 non-null    float64\n",
      " 5   Horas_Recomendadas_Revision  505 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 23.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10020 entries, 0 to 10019\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID_Orden             10020 non-null  int64  \n",
      " 1   ID_Equipo            10020 non-null  int64  \n",
      " 2   Fecha                10020 non-null  object \n",
      " 3   Tipo_Mantenimiento   10020 non-null  object \n",
      " 4   Costo_Mantenimiento  9971 non-null   float64\n",
      " 5   Duracion_Horas       10020 non-null  int64  \n",
      " 6   Ubicacion            10020 non-null  object \n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 548.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9000 entries, 0 to 8999\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ID_Registro       9000 non-null   int64  \n",
      " 1   ID_Equipo         9000 non-null   int64  \n",
      " 2   Fecha             9000 non-null   object \n",
      " 3   Temperatura_C     9000 non-null   float64\n",
      " 4   Vibracion_mm_s    9000 non-null   float64\n",
      " 5   Horas_Operativas  8960 non-null   float64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 422.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df_trabajo_caracteristicas_equipos.info())\n",
    "print(df_trabajo_historico_ordenes.info())\n",
    "print(df_trabajo_registros_condiciones.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero nulos=0\n",
      "No hay valores nulos\n",
      "Numero nulos=49\n",
      "Valores nulos eliminados\n",
      "Numero nulos=40\n",
      "Valores nulos eliminados\n"
     ]
    }
   ],
   "source": [
    "\n",
    "eliminar_nulos(df_trabajo_caracteristicas_equipos)\n",
    "eliminar_nulos(df_trabajo_historico_ordenes)\n",
    "eliminar_nulos(df_trabajo_registros_condiciones)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar duplicados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_duplicados(df):\n",
    "\n",
    "    # Identificar duplicados\n",
    "    duplicados = df[df.duplicated()]\n",
    "    print(\"Duplicados encontrados antes de la eliminación:\")\n",
    "    print(duplicados)\n",
    "\n",
    "    # Contar duplicados por columna\n",
    "    duplicados_count = df.duplicated().sum()\n",
    "    print(f\"Total de duplicados: {duplicados_count}\")\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicados eliminados.\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados antes de la eliminación:\n",
      "     ID_Equipo    Tipo_Equipo Fabricante Modelo  Potencia_kW  \\\n",
      "500          1      Compresor    Siemens   Z300       3429.0   \n",
      "501          2  Transformador    Siemens   Y200         75.0   \n",
      "502          3      Compresor        ABB   Z300       4526.0   \n",
      "503          4      Compresor         GE   X100       3981.0   \n",
      "504          5          Motor    Siemens   Y200        377.0   \n",
      "\n",
      "     Horas_Recomendadas_Revision  \n",
      "500                         7725  \n",
      "501                         7390  \n",
      "502                         5238  \n",
      "503                         8933  \n",
      "504                         5978  \n",
      "Total de duplicados: 5\n",
      "Duplicados eliminados.\n",
      "Duplicados encontrados antes de la eliminación:\n",
      "       ID_Orden  ID_Equipo                Fecha Tipo_Mantenimiento  \\\n",
      "10000         1         36  2020-01-01 00:00:00         Preventivo   \n",
      "10001         2        244  2020-01-01 01:00:00         Preventivo   \n",
      "10002         3        297  2020-01-01 02:00:00         Preventivo   \n",
      "10003         4        431  2020-01-01 03:00:00         Correctivo   \n",
      "10004         5        403  2020-01-01 04:00:00         Correctivo   \n",
      "10005         6        477  2020-01-01 05:00:00         Correctivo   \n",
      "10006         7        323  2020-01-01 06:00:00         Correctivo   \n",
      "10007         8        318  2020-01-01 07:00:00         Correctivo   \n",
      "10008         9        154  2020-01-01 08:00:00         Preventivo   \n",
      "10009        10        286  2020-01-01 09:00:00         Correctivo   \n",
      "10010        11        286  2020-01-01 10:00:00         Preventivo   \n",
      "10011        12        162  2020-01-01 11:00:00         Correctivo   \n",
      "10012        13        296  2020-01-01 12:00:00         Preventivo   \n",
      "10013        14        278  2020-01-01 13:00:00         Correctivo   \n",
      "10014        15        224  2020-01-01 14:00:00         Correctivo   \n",
      "10015        16        203  2020-01-01 15:00:00         Preventivo   \n",
      "10016        17        386  2020-01-01 16:00:00         Preventivo   \n",
      "10017        18        122  2020-01-01 17:00:00         Preventivo   \n",
      "10018        19         33  2020-01-01 18:00:00         Preventivo   \n",
      "10019        20        390  2020-01-01 19:00:00         Correctivo   \n",
      "\n",
      "       Costo_Mantenimiento  Duracion_Horas     Ubicacion  \n",
      "10000              6754.12               3  Planta Norte  \n",
      "10001              4274.63              35  Planta Norte  \n",
      "10002              5752.00              25  Planta Norte  \n",
      "10003              5690.14               8    Planta Sur  \n",
      "10004              7048.79              28  Planta Norte  \n",
      "10005              1519.65              40  Planta Norte  \n",
      "10006              9148.27              37    Planta Sur  \n",
      "10007              7784.49              19    Planta Sur  \n",
      "10008              4968.19              25    Planta Sur  \n",
      "10009              8351.02              21   Planta Este  \n",
      "10010              9287.54              28  Planta Oeste  \n",
      "10011              4055.65              34  Planta Norte  \n",
      "10012              3805.28              21    Planta Sur  \n",
      "10013              2214.52              17  Planta Norte  \n",
      "10014              4276.16               1  Planta Oeste  \n",
      "10015               320.94              46  Planta Norte  \n",
      "10016              2806.72              20  Planta Oeste  \n",
      "10017              8919.97              14  Planta Norte  \n",
      "10018              6522.17              24    Planta Sur  \n",
      "10019              1416.80              37    Planta Sur  \n",
      "Total de duplicados: 20\n",
      "Duplicados eliminados.\n",
      "Duplicados encontrados antes de la eliminación:\n",
      "Empty DataFrame\n",
      "Columns: [ID_Registro, ID_Equipo, Fecha, Temperatura_C, Vibracion_mm_s, Horas_Operativas]\n",
      "Index: []\n",
      "Total de duplicados: 0\n",
      "Duplicados eliminados.\n"
     ]
    }
   ],
   "source": [
    "procesar_duplicados(df_trabajo_caracteristicas_equipos)\n",
    "procesar_duplicados(df_trabajo_historico_ordenes)\n",
    "procesar_duplicados(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inconsistencias numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corregir_inconsistencias_numericas(df):\n",
    "    # Selección de columnas numéricas\n",
    "    numerical_columns_selector = selector(dtype_exclude=object)\n",
    "    numerical_columns = numerical_columns_selector(df)\n",
    "\n",
    "    # Corregir inconsistencias en campos numéricos\n",
    "    for col_name in numerical_columns:\n",
    "        df[col_name] = pd.to_numeric(df[col_name], errors='coerce')\n",
    "        df[col_name].fillna(df[col_name].median(), inplace=True)\n",
    "        print(f\"Inconsistencias corregidas en la columna numérica '{col_name}'.\")\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistencias corregidas en la columna numérica 'ID_Equipo'.\n",
      "Inconsistencias corregidas en la columna numérica 'Potencia_kW'.\n",
      "Inconsistencias corregidas en la columna numérica 'Horas_Recomendadas_Revision'.\n",
      "Inconsistencias corregidas en la columna numérica 'ID_Orden'.\n",
      "Inconsistencias corregidas en la columna numérica 'ID_Equipo'.\n",
      "Inconsistencias corregidas en la columna numérica 'Costo_Mantenimiento'.\n",
      "Inconsistencias corregidas en la columna numérica 'Duracion_Horas'.\n",
      "Inconsistencias corregidas en la columna numérica 'ID_Registro'.\n",
      "Inconsistencias corregidas en la columna numérica 'ID_Equipo'.\n",
      "Inconsistencias corregidas en la columna numérica 'Temperatura_C'.\n",
      "Inconsistencias corregidas en la columna numérica 'Vibracion_mm_s'.\n",
      "Inconsistencias corregidas en la columna numérica 'Horas_Operativas'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_17904\\3606547231.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(df[col_name].median(), inplace=True)\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_17904\\3606547231.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(df[col_name].median(), inplace=True)\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_17904\\3606547231.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col_name].fillna(df[col_name].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "corregir_inconsistencias_numericas(df_trabajo_caracteristicas_equipos)\n",
    "corregir_inconsistencias_numericas(df_trabajo_historico_ordenes)\n",
    "corregir_inconsistencias_numericas(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers a efectos practicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def procesar_outliers(df):\n",
    "  \n",
    "    # Esta función identifica y winsoriza outliers en las columnas numéricas de un DataFrame.\n",
    "\n",
    "    # Selección de columnas numéricas\n",
    "    numerical_columns_selector = selector(dtype_exclude=object)\n",
    "    numerical_columns = numerical_columns_selector(df)\n",
    "\n",
    "    # Identificación de outliers\n",
    "    IQR = df[numerical_columns].quantile(0.75) - df[numerical_columns].quantile(0.25)\n",
    "    lower_bound = df[numerical_columns].quantile(0.25) - (IQR * 1.5)\n",
    "    upper_bound = df[numerical_columns].quantile(0.75) + (IQR * 1.5)\n",
    "\n",
    "    # Función para winsorizar una columna\n",
    "    def winsorize_column(column, lower_bound, upper_bound):\n",
    "        return column.clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "\n",
    "    # Identificar y mostrar outliers antes de winsorización\n",
    "    outliers = df[numerical_columns][(df[numerical_columns] < lower_bound) | (df[numerical_columns] > upper_bound)]\n",
    "    print(\"Outliers encontrados antes de winsorización:\")\n",
    "    print(outliers)\n",
    "\n",
    "# Mostrar la suma de outliers por columna\n",
    "    outliers_count = outliers.count()\n",
    "    print(\"Los outlayers encontrados, suma total por columna:\")\n",
    "    for col_name, count in outliers_count.items():\n",
    "        print(f\"{col_name}: {count}\")\n",
    "\n",
    "    # Procesar todas las columnas con outliers\n",
    "    for col_name in numerical_columns:\n",
    "        df[col_name] = winsorize_column(df[col_name], lower_bound[col_name], upper_bound[col_name])\n",
    "\n",
    "    # Verificar outliers después de winsorización\n",
    "    outliers = df[numerical_columns][(df[numerical_columns] < lower_bound) | (df[numerical_columns] > upper_bound)]\n",
    "    print(\"Outliers - winsorized:\")\n",
    "    print(outliers.count())\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers encontrados antes de winsorización:\n",
      "     ID_Equipo  Potencia_kW  Horas_Recomendadas_Revision\n",
      "0          NaN          NaN                          NaN\n",
      "1          NaN          NaN                          NaN\n",
      "2          NaN          NaN                          NaN\n",
      "3          NaN          NaN                          NaN\n",
      "4          NaN          NaN                          NaN\n",
      "..         ...          ...                          ...\n",
      "495        NaN          NaN                          NaN\n",
      "496        NaN          NaN                          NaN\n",
      "497        NaN          NaN                          NaN\n",
      "498        NaN          NaN                          NaN\n",
      "499        NaN          NaN                          NaN\n",
      "\n",
      "[500 rows x 3 columns]\n",
      "Los outlayers encontrados, suma total por columna:\n",
      "ID_Equipo: 0\n",
      "Potencia_kW: 15\n",
      "Horas_Recomendadas_Revision: 0\n",
      "Outliers - winsorized:\n",
      "ID_Equipo                      0\n",
      "Potencia_kW                    0\n",
      "Horas_Recomendadas_Revision    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers encontrados antes de winsorización:\n",
      "      ID_Orden  ID_Equipo  Costo_Mantenimiento  Duracion_Horas\n",
      "0          NaN        NaN                  NaN             NaN\n",
      "1          NaN        NaN                  NaN             NaN\n",
      "2          NaN        NaN                  NaN             NaN\n",
      "3          NaN        NaN                  NaN             NaN\n",
      "4          NaN        NaN                  NaN             NaN\n",
      "...        ...        ...                  ...             ...\n",
      "9995       NaN        NaN                  NaN             NaN\n",
      "9996       NaN        NaN                  NaN             NaN\n",
      "9997       NaN        NaN                  NaN             NaN\n",
      "9998       NaN        NaN                  NaN             NaN\n",
      "9999       NaN        NaN                  NaN             NaN\n",
      "\n",
      "[9951 rows x 4 columns]\n",
      "Los outlayers encontrados, suma total por columna:\n",
      "ID_Orden: 0\n",
      "ID_Equipo: 0\n",
      "Costo_Mantenimiento: 30\n",
      "Duracion_Horas: 0\n",
      "Outliers - winsorized:\n",
      "ID_Orden               0\n",
      "ID_Equipo              0\n",
      "Costo_Mantenimiento    0\n",
      "Duracion_Horas         0\n",
      "dtype: int64\n",
      "Outliers encontrados antes de winsorización:\n",
      "      ID_Registro  ID_Equipo  Temperatura_C  Vibracion_mm_s  Horas_Operativas\n",
      "0             NaN        NaN            NaN             NaN               NaN\n",
      "1             NaN        NaN            NaN             NaN               NaN\n",
      "2             NaN        NaN            NaN             NaN               NaN\n",
      "3             NaN        NaN            NaN             NaN               NaN\n",
      "4             NaN        NaN            NaN             NaN               NaN\n",
      "...           ...        ...            ...             ...               ...\n",
      "8995          NaN        NaN            NaN             NaN               NaN\n",
      "8996          NaN        NaN            NaN             NaN               NaN\n",
      "8997          NaN        NaN            NaN             NaN               NaN\n",
      "8998          NaN        NaN            NaN             NaN               NaN\n",
      "8999          NaN        NaN            NaN             NaN               NaN\n",
      "\n",
      "[8960 rows x 5 columns]\n",
      "Los outlayers encontrados, suma total por columna:\n",
      "ID_Registro: 0\n",
      "ID_Equipo: 0\n",
      "Temperatura_C: 30\n",
      "Vibracion_mm_s: 24\n",
      "Horas_Operativas: 0\n",
      "Outliers - winsorized:\n",
      "ID_Registro         0\n",
      "ID_Equipo           0\n",
      "Temperatura_C       0\n",
      "Vibracion_mm_s      0\n",
      "Horas_Operativas    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "procesar_outliers(df_trabajo_caracteristicas_equipos)\n",
    "procesar_outliers(df_trabajo_historico_ordenes)\n",
    "procesar_outliers(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_fechas(df):\n",
    "\n",
    "    # Selección de columnas de tipo fecha\n",
    "    date_columns_selector = selector(dtype_include='object')\n",
    "    date_columns = date_columns_selector(df)\n",
    "\n",
    "    # Transformar columnas de fecha a formato datetime\n",
    "    for col_name in date_columns:\n",
    "        try:\n",
    "            df[col_name] = pd.to_datetime(df[col_name])\n",
    "            print(f\"Columna '{col_name}' transformada a formato datetime.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al transformar la columna '{col_name}': {e}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al transformar la columna 'Tipo_Equipo': Unknown datetime string format, unable to parse: Compresor, at position 0\n",
      "Error al transformar la columna 'Fabricante': Unknown datetime string format, unable to parse: Siemens, at position 0\n",
      "Error al transformar la columna 'Modelo': Unknown datetime string format, unable to parse: Z300, at position 0\n",
      "Columna 'Fecha' transformada a formato datetime.\n",
      "Error al transformar la columna 'Tipo_Mantenimiento': Unknown datetime string format, unable to parse: Preventivo, at position 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_17904\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_17904\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_17904\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_17904\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_17904\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al transformar la columna 'Ubicacion': Unknown datetime string format, unable to parse: Planta Norte, at position 0\n",
      "Columna 'Fecha' transformada a formato datetime.\n"
     ]
    }
   ],
   "source": [
    "transformar_fechas(df_trabajo_caracteristicas_equipos)\n",
    "transformar_fechas(df_trabajo_historico_ordenes)\n",
    "transformar_fechas(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevas columnas, se me ocurren diferencias entre fechas de correctivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informacion tabla ordenes: df_trabajo_historico_ordenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nueva columna frecuencia de correctivo por equipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar solo los registros de mantenimiento correctivo\n",
    "df_mantenimiento_correctivo = df_trabajo_historico_ordenes[df_trabajo_historico_ordenes['Tipo_Mantenimiento'] == 'Correctivo']\n",
    "\n",
    "# Calcular la frecuencia de mantenimiento correctivo para cada equipo\n",
    "df_frecuencia_mantenimiento_correctivo = df_mantenimiento_correctivo['ID_Equipo'].value_counts()\n",
    "\n",
    "# Mapear la frecuencia al dataframe del histórico de órdenes\n",
    "df_trabajo_historico_ordenes['Frecuencia de mantenimiento correctivo'] = df_trabajo_historico_ordenes['ID_Equipo'].map(df_frecuencia_mantenimiento_correctivo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informacion tabla ordenes: df_trabajo_registros_condiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir la columna 'Fecha' al formato datetime\n",
    "df_trabajo_registros_condiciones['Fecha'] = pd.to_datetime(df_trabajo_registros_condiciones['Fecha'])\n",
    "\n",
    "# Extraer el mes y el año de la columna 'Fecha'\n",
    "df_trabajo_registros_condiciones['Mes'] = df_trabajo_registros_condiciones['Fecha'].dt.to_period('M')\n",
    "\n",
    "# Agrupar por 'ID_Equipo' y 'Mes', luego calcular la media de 'Horas_Operativas'\n",
    "media_horas = df_trabajo_registros_condiciones.groupby(['ID_Equipo', 'Mes'])['Horas_Operativas'].mean().reset_index()\n",
    "\n",
    "# Unir el DataFrame mean_hours al DataFrame original\n",
    "df_trabajo_registros_condiciones = df_trabajo_registros_condiciones.merge(media_horas, on=['ID_Equipo', 'Mes'], suffixes=('', '_mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8960 entries, 0 to 8959\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   ID_Registro            8960 non-null   int64         \n",
      " 1   ID_Equipo              8960 non-null   int64         \n",
      " 2   Fecha                  8960 non-null   datetime64[ns]\n",
      " 3   Temperatura_C          8960 non-null   float64       \n",
      " 4   Vibracion_mm_s         8960 non-null   float64       \n",
      " 5   Horas_Operativas       8960 non-null   float64       \n",
      " 6   Mes                    8960 non-null   period[M]     \n",
      " 7   Horas_Operativas_mean  8960 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(4), int64(2), period[M](1)\n",
      "memory usage: 560.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_trabajo_registros_condiciones.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabado de fichero de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trabajo_caracteristicas_equipos.to_csv(\"../output/df_caracteristicas_equipos_tratados.csv\", index=False)\n",
    "df_trabajo_historico_ordenes.to_csv(\"../output/df_historico_ordenes_tratados.csv\", index=False)\n",
    "df_trabajo_registros_condiciones.to_csv(\"../output/df_registros_condiciones_tratados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lectura ficheros de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_trabajo_caracteristicas_equipos = pd.read_csv(\"../output/df_caracteristicas_equipos_tratados.csv\")\n",
    "    df_trabajo_historico_ordenes = pd.read_csv(\"../output/df_historico_ordenes_tratados.csv\")\n",
    "    df_trabajo_registros_condiciones = pd.read_csv(\"../output/df_registros_condiciones_tratados.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar los datos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convertir las columnas 'Fecha' a formato datetime\n",
    "df_trabajo_historico_ordenes['Fecha'] = pd.to_datetime(df_trabajo_historico_ordenes['Fecha'])\n",
    "df_trabajo_registros_condiciones['Fecha'] = pd.to_datetime(df_trabajo_registros_condiciones['Fecha'])\n",
    "\n",
    "# Mezclar los dataframes basándose en la fecha más cercana\n",
    "merged_df = pd.merge_asof(df_trabajo_historico_ordenes.sort_values('Fecha'), \n",
    "                          df_trabajo_registros_condiciones.sort_values('Fecha'), \n",
    "                          on='Fecha', \n",
    "                          by='ID_Equipo', \n",
    "                          direction='nearest')\n",
    "\n",
    "# Mezclar con el dataframe de características de equipos\n",
    "df_final = pd.merge(merged_df, df_trabajo_caracteristicas_equipos, on='ID_Equipo', how='left')\n",
    "\n",
    "# Guardar el dataframe final mezclado en un nuevo archivo CSV\n",
    "df_final.to_csv('../output/Datos_Fusionadosv0.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nueva columna Fecha esperada revision (esta despues del merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar la columna 'Fecha_Revision' con los mismos valores que 'Fecha'\n",
    "df_final['Fecha_Revision'] = df_final['Fecha']\n",
    "\n",
    "# Iterar a través del dataframe y actualizar 'Fecha_Revision' para los registros de tipo Preventivo\n",
    "for i in range(1, len(df_final)):\n",
    "    if df_final.loc[i, 'Tipo_Mantenimiento'] == 'Preventivo':\n",
    "        df_final.loc[i, 'Fecha_Revision'] = df_final.loc[i, 'Fecha'] + pd.to_timedelta(df_final.loc[i, 'Horas_Recomendadas_Revision'], unit='h')\n",
    "    elif df_final.loc[i, 'Tipo_Mantenimiento'] == 'Correctivo':\n",
    "        df_final.loc[i, 'Fecha_Revision'] = df_final.loc[i-1, 'Fecha_Revision']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardado Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el dataframe final mezclado en un nuevo archivo CSV\n",
    "df_final.to_csv('../output/Datos_Fusionadosv1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
