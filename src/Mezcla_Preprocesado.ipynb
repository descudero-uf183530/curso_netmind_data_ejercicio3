{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los tres datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al cargar los datos: <urlopen error [Errno 11001] getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "# Cargar los tres datasets DES:\n",
    "base_url = \"https://raw.githubusercontent.com/ricardoahumada/DataExpert/refs/heads/main/etapa2/data/\"\n",
    "\n",
    "try:\n",
    "    df_original_caracteristicas_equipos = pd.read_csv(base_url + 'Caracteristicas_Equipos.csv')\n",
    "    df_original_historico_ordenes = pd.read_csv(base_url + 'Historicos_Ordenes.csv')\n",
    "    df_original_registros_condiciones = pd.read_csv(base_url + 'Registros_Condiciones.csv')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar los datos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar copia en local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Los guardamos en local los originales para no depender.\n",
    "\n",
    "df_original_caracteristicas_equipos.to_csv(\"../output/df_caracteristicas_equipos.csv\", index=False)\n",
    "df_original_historico_ordenes.to_csv(\"../output/df_historico_ordenes.csv\", index=False)\n",
    "df_original_registros_condiciones.to_csv(\"../output/df_registros_condiciones.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los tres datasets desde local:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (572511450.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[43], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    **# Cargar los tres datasets desde local:**\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los tres datasets desde local:\n",
    "\n",
    "\n",
    "try:\n",
    "    df_trabajo_caracteristicas_equipos = pd.read_csv(\"../output/df_caracteristicas_equipos.csv\")\n",
    "    df_trabajo_historico_ordenes = pd.read_csv(\"../output/df_historico_ordenes.csv\")\n",
    "    df_trabajo_registros_condiciones = pd.read_csv(\"../output/df_registros_condiciones.csv\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar los datos: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesado por separado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_nulos(df):\n",
    "\n",
    "# Esta función verifica si hay valores nulos en el DataFrame.\n",
    "    \n",
    "    nulos = df.isnull().sum().sum()\n",
    "    print(\"Numero nulos=\" + str(nulos))\n",
    "\n",
    "    if nulos != 0:\n",
    "        df.dropna(inplace=True)\n",
    "        print(\"Valores nulos eliminados\")\n",
    "    else:\n",
    "        print(\"No hay valores nulos\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 6 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   ID_Equipo                    505 non-null    int64  \n",
      " 1   Tipo_Equipo                  505 non-null    object \n",
      " 2   Fabricante                   505 non-null    object \n",
      " 3   Modelo                       505 non-null    object \n",
      " 4   Potencia_kW                  505 non-null    float64\n",
      " 5   Horas_Recomendadas_Revision  505 non-null    int64  \n",
      "dtypes: float64(1), int64(2), object(3)\n",
      "memory usage: 23.8+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10020 entries, 0 to 10019\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID_Orden             10020 non-null  int64  \n",
      " 1   ID_Equipo            10020 non-null  int64  \n",
      " 2   Fecha                10020 non-null  object \n",
      " 3   Tipo_Mantenimiento   10020 non-null  object \n",
      " 4   Costo_Mantenimiento  9971 non-null   float64\n",
      " 5   Duracion_Horas       10020 non-null  int64  \n",
      " 6   Ubicacion            10020 non-null  object \n",
      "dtypes: float64(1), int64(3), object(3)\n",
      "memory usage: 548.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9000 entries, 0 to 8999\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   ID_Registro       9000 non-null   int64  \n",
      " 1   ID_Equipo         9000 non-null   int64  \n",
      " 2   Fecha             9000 non-null   object \n",
      " 3   Temperatura_C     9000 non-null   float64\n",
      " 4   Vibracion_mm_s    9000 non-null   float64\n",
      " 5   Horas_Operativas  8960 non-null   float64\n",
      "dtypes: float64(3), int64(2), object(1)\n",
      "memory usage: 422.0+ KB\n",
      "None\n",
      "Numero nulos=0\n",
      "No hay valores nulos\n",
      "Numero nulos=49\n",
      "Valores nulos eliminados\n",
      "Numero nulos=40\n",
      "Valores nulos eliminados\n"
     ]
    }
   ],
   "source": [
    "print(df_trabajo_caracteristicas_equipos.info())\n",
    "print(df_trabajo_historico_ordenes.info())\n",
    "print(df_trabajo_registros_condiciones.info())\n",
    "\n",
    "\n",
    "#nulos = df_trabajo_caracteristicas_equipos.isnull().sum().sum()\n",
    "#print(\"Numero nulos=\" + str(nulos))\n",
    "\n",
    "#if nulos != 0:\n",
    "#    df_trabajo_caracteristicas_equipos.dropna(inplace=True)\n",
    "#    print(\"Valores nulos eliminados\")\n",
    "#else:\n",
    "#    print(\"No hay valores nulos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eliminar_nulos(df_trabajo_caracteristicas_equipos)\n",
    "eliminar_nulos(df_trabajo_historico_ordenes)\n",
    "eliminar_nulos(df_trabajo_registros_condiciones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def procesar_outliers(df):\n",
    "  \n",
    "    # Esta función identifica y winsoriza outliers en las columnas numéricas de un DataFrame.\n",
    "\n",
    "    # Selección de columnas numéricas\n",
    "    numerical_columns_selector = selector(dtype_exclude=object)\n",
    "    numerical_columns = numerical_columns_selector(df)\n",
    "\n",
    "    # Identificación de outliers\n",
    "    IQR = df[numerical_columns].quantile(0.75) - df[numerical_columns].quantile(0.25)\n",
    "    lower_bound = df[numerical_columns].quantile(0.25) - (IQR * 1.5)\n",
    "    upper_bound = df[numerical_columns].quantile(0.75) + (IQR * 1.5)\n",
    "\n",
    "    # Función para winsorizar una columna\n",
    "    def winsorize_column(column, lower_bound, upper_bound):\n",
    "        return column.clip(lower=lower_bound, upper=upper_bound)\n",
    "    \n",
    "\n",
    "    # Identificar y mostrar outliers antes de winsorización\n",
    "    outliers = df[numerical_columns][(df[numerical_columns] < lower_bound) | (df[numerical_columns] > upper_bound)]\n",
    "    print(\"Outliers encontrados antes de winsorización:\")\n",
    "    print(outliers)\n",
    "\n",
    "# Mostrar la suma de outliers por columna\n",
    "    outliers_count = outliers.count()\n",
    "    print(\"Los outlayers encontrados, suma total por columna:\")\n",
    "    for col_name, count in outliers_count.items():\n",
    "        print(f\"{col_name}: {count}\")\n",
    "\n",
    "    # Procesar todas las columnas con outliers\n",
    "    for col_name in numerical_columns:\n",
    "        df[col_name] = winsorize_column(df[col_name], lower_bound[col_name], upper_bound[col_name])\n",
    "\n",
    "    # Verificar outliers después de winsorización\n",
    "    outliers = df[numerical_columns][(df[numerical_columns] < lower_bound) | (df[numerical_columns] > upper_bound)]\n",
    "    print(\"Outliers - winsorized:\")\n",
    "    print(outliers.count())\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns ['ID_Equipo', 'Potencia_kW', 'Horas_Recomendadas_Revision']\n",
      "Categorical columns ['Tipo_Equipo', 'Fabricante', 'Modelo']\n"
     ]
    }
   ],
   "source": [
    "# Extraer columnas numéricas y categóricas\n",
    "#from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "#numerical_columns_selector = selector(dtype_exclude=object)\n",
    "#categorical_columns_selector = selector(dtype_include=object)\n",
    "\n",
    "#numerical_columns = numerical_columns_selector(df_trabajo_caracteristicas_equipos)\n",
    "#categorical_columns = categorical_columns_selector(df_trabajo_caracteristicas_equipos)\n",
    "\n",
    "#print(\"Numerical columns\", numerical_columns)\n",
    "#print(\"Categorical columns\", categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lower_bound ID_Equipo                       -634.0\n",
      "Potencia_kW                    -6882.0\n",
      "Horas_Recomendadas_Revision   -11367.0\n",
      "dtype: float64\n",
      "upper_bound ID_Equipo                       1130.0\n",
      "Potencia_kW                    11990.0\n",
      "Horas_Recomendadas_Revision    21974.0\n",
      "dtype: float64\n",
      "Outliers:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID_Equipo                       0\n",
       "Potencia_kW                    15\n",
       "Horas_Recomendadas_Revision     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outliers\n",
    "\n",
    "# identificación\n",
    "# IQR = df_trabajo_caracteristicas_equipos[numerical_columns].quantile(0.75) - df_trabajo_caracteristicas_equipos[numerical_columns].quantile(0.25)\n",
    "#lower_bound = df_trabajo_caracteristicas_equipos[numerical_columns].quantile(0.25) - (IQR * 3)\n",
    "#upper_bound = df_trabajo_caracteristicas_equipos[numerical_columns].quantile(0.75) + (IQR * 3)\n",
    "\n",
    "#print('lower_bound',lower_bound)\n",
    "#print('upper_bound',upper_bound)\n",
    "\n",
    "#outliers = df_trabajo_caracteristicas_equipos[numerical_columns][(df_trabajo_caracteristicas_equipos[numerical_columns] < lower_bound) | (df_trabajo_caracteristicas_equipos[numerical_columns] > upper_bound)]\n",
    "\n",
    "#print(\"Outliers:\")\n",
    "#outliers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Potencia_kW'], dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reemplazo\n",
    "\n",
    "# columnas con outliers\n",
    "#columns_with_outliers = outliers.columns[outliers.count() > 0]\n",
    "#columns_with_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para winsorizar una columna\n",
    "#def winsorize_column(column, lower_bound, upper_bound):\n",
    "#    return column.clip(lower=lower_bound, upper=upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers - winsorized:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ID_Equipo                      0\n",
       "Potencia_kW                    0\n",
       "Horas_Recomendadas_Revision    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# procesamos todas las comumnas con outliers\n",
    "#for col_name in columns_with_outliers:\n",
    "#    df_trabajo_caracteristicas_equipos[col_name] = winsorize_column(df_trabajo_caracteristicas_equipos[col_name], lower_bound[col_name], upper_bound[col_name])\n",
    "\n",
    "#outliers = df_trabajo_caracteristicas_equipos[numerical_columns][(df_trabajo_caracteristicas_equipos[numerical_columns] < lower_bound) | (df_trabajo_caracteristicas_equipos[numerical_columns] > upper_bound)]\n",
    "\n",
    "#print(\"Outliers - winsorized:\")\n",
    "#outliers.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers encontrados antes de winsorización:\n",
      "     ID_Equipo  Potencia_kW  Horas_Recomendadas_Revision\n",
      "0          NaN          NaN                          NaN\n",
      "1          NaN          NaN                          NaN\n",
      "2          NaN          NaN                          NaN\n",
      "3          NaN          NaN                          NaN\n",
      "4          NaN          NaN                          NaN\n",
      "..         ...          ...                          ...\n",
      "500        NaN          NaN                          NaN\n",
      "501        NaN          NaN                          NaN\n",
      "502        NaN          NaN                          NaN\n",
      "503        NaN          NaN                          NaN\n",
      "504        NaN          NaN                          NaN\n",
      "\n",
      "[505 rows x 3 columns]\n",
      "Los outlayers encontrados, suma total por columna:\n",
      "ID_Equipo: 0\n",
      "Potencia_kW: 0\n",
      "Horas_Recomendadas_Revision: 0\n",
      "Outliers - winsorized:\n",
      "ID_Equipo                      0\n",
      "Potencia_kW                    0\n",
      "Horas_Recomendadas_Revision    0\n",
      "dtype: int64\n",
      "Outliers encontrados antes de winsorización:\n",
      "       ID_Orden  ID_Equipo  Costo_Mantenimiento  Duracion_Horas\n",
      "0           NaN        NaN                  NaN             NaN\n",
      "1           NaN        NaN                  NaN             NaN\n",
      "2           NaN        NaN                  NaN             NaN\n",
      "3           NaN        NaN                  NaN             NaN\n",
      "4           NaN        NaN                  NaN             NaN\n",
      "...         ...        ...                  ...             ...\n",
      "10015       NaN        NaN                  NaN             NaN\n",
      "10016       NaN        NaN                  NaN             NaN\n",
      "10017       NaN        NaN                  NaN             NaN\n",
      "10018       NaN        NaN                  NaN             NaN\n",
      "10019       NaN        NaN                  NaN             NaN\n",
      "\n",
      "[9971 rows x 4 columns]\n",
      "Los outlayers encontrados, suma total por columna:\n",
      "ID_Orden: 0\n",
      "ID_Equipo: 0\n",
      "Costo_Mantenimiento: 30\n",
      "Duracion_Horas: 0\n",
      "Outliers - winsorized:\n",
      "ID_Orden               0\n",
      "ID_Equipo              0\n",
      "Costo_Mantenimiento    0\n",
      "Duracion_Horas         0\n",
      "dtype: int64\n",
      "Outliers encontrados antes de winsorización:\n",
      "      ID_Registro  ID_Equipo  Temperatura_C  Vibracion_mm_s  Horas_Operativas\n",
      "0             NaN        NaN            NaN             NaN               NaN\n",
      "1             NaN        NaN            NaN             NaN               NaN\n",
      "2             NaN        NaN            NaN             NaN               NaN\n",
      "3             NaN        NaN            NaN             NaN               NaN\n",
      "4             NaN        NaN            NaN             NaN               NaN\n",
      "...           ...        ...            ...             ...               ...\n",
      "8995          NaN        NaN            NaN             NaN               NaN\n",
      "8996          NaN        NaN            NaN             NaN               NaN\n",
      "8997          NaN        NaN            NaN             NaN               NaN\n",
      "8998          NaN        NaN            NaN             NaN               NaN\n",
      "8999          NaN        NaN            NaN             NaN               NaN\n",
      "\n",
      "[8960 rows x 5 columns]\n",
      "Los outlayers encontrados, suma total por columna:\n",
      "ID_Registro: 0\n",
      "ID_Equipo: 0\n",
      "Temperatura_C: 30\n",
      "Vibracion_mm_s: 24\n",
      "Horas_Operativas: 0\n",
      "Outliers - winsorized:\n",
      "ID_Registro         0\n",
      "ID_Equipo           0\n",
      "Temperatura_C       0\n",
      "Vibracion_mm_s      0\n",
      "Horas_Operativas    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "procesar_outliers(df_trabajo_caracteristicas_equipos)\n",
    "procesar_outliers(df_trabajo_historico_ordenes)\n",
    "procesar_outliers(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_duplicados(df):\n",
    "\n",
    "    # Identificar duplicados\n",
    "    duplicados = df[df.duplicated()]\n",
    "    print(\"Duplicados encontrados antes de la eliminación:\")\n",
    "    print(duplicados)\n",
    "\n",
    "    # Contar duplicados por columna\n",
    "    duplicados_count = df.duplicated().sum()\n",
    "    print(f\"Total de duplicados: {duplicados_count}\")\n",
    "\n",
    "    # Eliminar duplicados\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(\"Duplicados eliminados.\")\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados encontrados antes de la eliminación:\n",
      "Empty DataFrame\n",
      "Columns: [ID_Equipo, Tipo_Equipo, Fabricante, Modelo, Potencia_kW, Horas_Recomendadas_Revision]\n",
      "Index: []\n",
      "Total de duplicados: 0\n",
      "Duplicados eliminados.\n",
      "Duplicados encontrados antes de la eliminación:\n",
      "Empty DataFrame\n",
      "Columns: [ID_Orden, ID_Equipo, Fecha, Tipo_Mantenimiento, Costo_Mantenimiento, Duracion_Horas, Ubicacion]\n",
      "Index: []\n",
      "Total de duplicados: 0\n",
      "Duplicados eliminados.\n",
      "Duplicados encontrados antes de la eliminación:\n",
      "Empty DataFrame\n",
      "Columns: [ID_Registro, ID_Equipo, Fecha, Temperatura_C, Vibracion_mm_s, Horas_Operativas]\n",
      "Index: []\n",
      "Total de duplicados: 0\n",
      "Duplicados eliminados.\n"
     ]
    }
   ],
   "source": [
    "procesar_duplicados(df_trabajo_caracteristicas_equipos)\n",
    "procesar_duplicados(df_trabajo_historico_ordenes)\n",
    "procesar_duplicados(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transformar Fechas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformar_fechas(df):\n",
    "\n",
    "    # Selección de columnas de tipo fecha\n",
    "    date_columns_selector = selector(dtype_include='object')\n",
    "    date_columns = date_columns_selector(df)\n",
    "\n",
    "    # Transformar columnas de fecha a formato datetime\n",
    "    for col_name in date_columns:\n",
    "        try:\n",
    "            df[col_name] = pd.to_datetime(df[col_name])\n",
    "            print(f\"Columna '{col_name}' transformada a formato datetime.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al transformar la columna '{col_name}': {e}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al transformar la columna 'Tipo_Equipo': Unknown datetime string format, unable to parse: Compresor, at position 0\n",
      "Error al transformar la columna 'Fabricante': Unknown datetime string format, unable to parse: Siemens, at position 0\n",
      "Error al transformar la columna 'Modelo': Unknown datetime string format, unable to parse: Z300, at position 0\n",
      "Columna 'Fecha' transformada a formato datetime.\n",
      "Error al transformar la columna 'Tipo_Mantenimiento': Unknown datetime string format, unable to parse: Preventivo, at position 0\n",
      "Error al transformar la columna 'Ubicacion': Unknown datetime string format, unable to parse: Planta Norte, at position 0\n",
      "Columna 'Fecha' transformada a formato datetime.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_5076\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_5076\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_5076\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_5076\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n",
      "C:\\Users\\UF775634\\AppData\\Local\\Temp\\ipykernel_5076\\2924473544.py:10: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col_name] = pd.to_datetime(df[col_name])\n"
     ]
    }
   ],
   "source": [
    "transformar_fechas(df_trabajo_caracteristicas_equipos)\n",
    "transformar_fechas(df_trabajo_historico_ordenes)\n",
    "transformar_fechas(df_trabajo_registros_condiciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevas columnas, se me ocurren diferencias entre fechas de correctivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trabajo_caracteristicas_equipos.to_csv(\"../output/df_caracteristicas_equipos_tratados.csv\", index=False)\n",
    "df_trabajo_historico_ordenes.to_csv(\"../output/df_historico_ordenes_tratados.csv\", index=False)\n",
    "df_trabajo_registros_condiciones.to_csv(\"../output/df_registros_condiciones_tratados.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
